{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will draw couple of plots during the lecture. We activate matplotlib to show the plots inline in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` provides state-of-the-art machine learning algorithms. \n",
    "These algorithms, however, cannot be directly used on raw data. Raw data needs to be preprocessed beforehand. Thus, besides machine learning algorithms, `scikit-learn` provides a set of preprocessing methods. Furthermore, `scikit-learn` provides connectors for pipelining these estimators (i.e., transformer, regressor, classifier, clusterer, etc.).\n",
    "\n",
    "In this lecture, we will present the set of `scikit-learn` functionalities allowing for pipelining estimators, evaluating those pipelines, tuning those pipelines using hyper-parameters optimization, and creating complex preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic use-case: train and test a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first example, we will train and test a classifier on a dataset. We will use this example to recall the API of `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `digits` dataset which is a dataset of hand-written digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in `X` contains the intensities of the 64 image pixels. For each sample in `X`, we get the ground-truth `y` indicating the digit written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0].reshape(8, 8), cmap='gray');\n",
    "plt.axis('off')\n",
    "print('The digit in the image is {}'.format(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, we should evaluate our model by training and testing it on distinct sets of data. `train_test_split` is a utility function to split the data into two independent sets. The `stratify` parameter enforces the classes distribution of the train and test datasets to be the same than the one of the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have independent training and testing sets, we can learn a machine learning model using the `fit` method. We will use the `score` method to test this method, relying on the default accuracy metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization strength increases in lambda\n",
    "slides: lambda\n",
    "sklearn:\n",
    "regression: alpha = lambda\n",
    "classification: C = 1/lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=5000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API of `scikit-learn` is consistent across classifiers. Thus, we can easily replace the `LogisticRegression` classifier by a `RandomForestClassifier`. These changes are minimal and only related to the creation of the classifier instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Do the following exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the breast cancer dataset. Import the functions `load_breast_cancer` from `sklearn.datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X_breast, y_breast = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_breast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_breast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_breast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the dataset to keep 30% of it for testing using `sklearn.model_selection.train_test_split`. Make sure to stratify the data (i.e., use the `stratify` parameter) and set the `random_state` to `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_breast_train, X_breast_test, y_breast_train, y_breast_test = train_test_split(X_breast, y_breast, stratify=y_breast, random_state=0, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train a supervised classifier using the training data using GradientBoostingClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_breast_train, y_breast_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the fitted classifier to predict the classification labels for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_breast_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the balanced accuracy on the testing set. You need to import `balanced_accuracy_score` from `sklearn.metrics`\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "accuracy = balanced_accuracy_score(y_breast_test, y_pred)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. More advanced use-case: preprocess the data before training and testing a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Standardize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing might be required before learning a model. For instance, a user could be interested in creating hand-crafted features or an algorithm might make some apriori assumptions about the data. \n",
    "\n",
    "In our case, the solver used by the `LogisticRegression` expects the data to be normalized. Thus, we need to standardize the data before training the model. To observe this necessary condition, we will check the number of iterations required to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=5000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print('{} required {} iterations to be fitted'.format(clf.__class__.__name__, clf.n_iter_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# X_train_scaled = scaler.fit(X_train) #find min and max of each feature in the training set\n",
    "\n",
    "# X_train_scaled = scaler.transform(X_train) #normalize the training set (using the min and max found above)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test) #normalize the testing set (using the min and max found above)\n",
    "\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "accuracy = clf.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))\n",
    "print('{} required {} iterations to be fitted'.format(clf.__class__.__name__, clf.n_iter_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "accuracy = clf.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))\n",
    "print('{} required {} iterations to be fitted'.format(clf.__class__.__name__, clf.n_iter_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MinMaxScaler` transformer is used to normalise the data. Other scalers include `StandardScaler`, `RobustScaler`, and `Normalizer`. The scaler should be applied in the following way: learn (i.e., `fit` method) the statistics on a training set and standardize (i.e., `transform` method) both the training and testing sets. Finally, we will train and test the model and the scaled datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By scaling the data, the convergence of the model happened much faster than with the unscaled data.\n",
    "\n",
    "for any feature\n",
    "standardscaler: (x-mean)/standard deviation;\n",
    "minmaxscaler: (x-min)/(max-min)\n",
    "robustscaler: (x-median)/(75% quantile - 25% quantile)\n",
    "\n",
    "for any observation:\n",
    "normalizer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/scaler_comparison_scatter.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The wrong preprocessing patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We highlighted how to preprocess and adequately train a machine learning model. It is also interesting to spot what would be the wrong way of preprocessing data. There are two potential mistakes which are easy to make but easy to spot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first pattern is to standardize the data before spliting the full set into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train_prescaled, X_test_prescaled, y_train_prescaled, y_test_prescaled = train_test_split(\n",
    "    X_scaled, y, stratify=y, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_prescaled, y_train_prescaled)\n",
    "accuracy = clf.score(X_test_prescaled, y_test_prescaled)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second pattern is to standardize the training and testing sets independently. It comes back to call the `fit` methods on both training and testing sets. Thus, the training and testing sets are standardized differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_prescaled = scaler.fit_transform(X_train)\n",
    "X_test_prescaled = scaler.fit_transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_prescaled, y_train)\n",
    "accuracy = clf.score(X_test_prescaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/no_separate_scaling.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Keep it simple, stupid: use the pipeline connector from `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two previous patterns are an issue with data leaking. However, this is difficult to prevent such a mistake when one has to do the preprocessing by hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "mglearn.plots.plot_improper_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, `scikit-learn` introduced the `Pipeline` object. It sequentially connects several transformers and a classifier (or a regressor). We can create a pipeline as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_proper_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
    "                       ('clf', LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this pipeline contains the parameters of both the scaler and the classifier. The general pipeline can join any number of estimators together. For example, you could build a pipeline containing feature extraction, feature selection, scaling, and classification, for a total of four steps. Similarly, the last step could be regression or clustering instead of classification. \n",
    "\n",
    "Sometimes, it can be tedious to give a name to each estimator in the pipeline. `make_pipeline` will give a name automatically to each estimator which is the lower case of the class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42, max_iter=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline will have an identical API. We use `fit` to train the classifier and `score` to check the accuracy. However, calling `fit` will call the method `fit_transform` of all transformers in the pipeline. Calling `score` (or `predict` and `predict_proba`) will call internally `transform` of all transformers in the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(pipe.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check all the parameters of the pipeline using `get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Exercise\n",
    "\n",
    "Reuse the breast dataset of the first exercise to train a `SGDClassifier` which you can import from `linear_model`. Make a pipeline with this classifier and a `StandardScaler` transformer imported from `sklearn.preprocessing`. Train and test this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000))\n",
    "pipe.fit(X_breast_train, y_breast_train)\n",
    "y_pred = pipe.predict(X_breast_test)\n",
    "accuracy = balanced_accuracy_score(y_breast_test, y_pred)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(pipe.__class__.__name__, accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Interactions and polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "boston = load_boston()\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    boston.data, boston.target, random_state=0)\n",
    "\n",
    "# rescale data\n",
    "scaler = MinMaxScaler()\n",
    "X_train2_scaled = scaler.fit_transform(X_train2)\n",
    "X_test2_scaled = scaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2).fit(X_train2_scaled)\n",
    "X_train2_poly = poly.transform(X_train2_scaled)\n",
    "X_test2_poly = poly.transform(X_test2_scaled)\n",
    "print(\"X_train.shape: {}\".format(X_train2.shape))\n",
    "print(\"X_train_poly.shape: {}\".format(X_train2_poly.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Polynomial feature names:\\n{}\".format(poly.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge().fit(X_train2_scaled, y_train2)\n",
    "print(\"Score without interactions: {:.3f}\".format(\n",
    "    ridge.score(X_test2_scaled, y_test2)))\n",
    "ridge = Ridge().fit(X_train2_poly, y_train2)\n",
    "print(\"Score with interactions: {:.3f}\".format(\n",
    "    ridge.score(X_test2_poly, y_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100).fit(X_train2_scaled, y_train2)\n",
    "print(\"Score without interactions: {:.3f}\".format(\n",
    "    rf.score(X_test2_scaled, y_test2)))\n",
    "rf = RandomForestRegressor(n_estimators=100).fit(X_train2_poly, y_train2)\n",
    "print(\"Score with interactions: {:.3f}\".format(rf.score(X_test2_poly, y_test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. When more is better than less: cross-validation instead of single split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data is necessary to evaluate the statistical model performance. However, it reduces the number of samples which can be used to learn the model. Therefore, one should use cross-validation whenever possible. Having multiple splits will give information about the model stability as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. How to split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "print(\"Iris labels:\\n{}\".format(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/iris_petal_sepal.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multiclass_barchart.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mglearn\n",
    "mglearn.plots.plot_stratified_cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/kfold_cv.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=3)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5)\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "      cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "    cross_val_score(logreg, iris.data, iris.target, cv=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/stratified_cv.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=3)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave-one-out cross-validation\n",
    "High variance, takes a long time; Not a good idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "logreg = LogisticRegression(max_iter = 5000)\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=loo)\n",
    "print(\"Number of cv iterations: \", len(scores))\n",
    "print(\"Mean accuracy: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle-split cross-validation\n",
    "Number of iterations and test set size independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/shuffle_split_cv.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_shuffle_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=shuffle_split)\n",
    "print(\"Cross-validation scores:\\n{}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross-validation scores:\\n{}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified Shuffle-split cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "shuffle_split = StratifiedShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=shuffle_split)\n",
    "print(\"Cross-validation scores:\\n{}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Cross-validation scores:\\n{}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-validation with groups\n",
    "Cross-validation with non-iid data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/group_kfold.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_group_kfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import GroupKFold\n",
    "# create synthetic dataset\n",
    "X3, y3 = make_blobs(n_samples=12, random_state=0)\n",
    "# assume the first three samples belong to the same group,\n",
    "# then the next four, etc.\n",
    "groups = [0, 0, 0, 1, 1, 1, 1, 2, 2, 3, 3, 3]\n",
    "scores = cross_val_score(logreg, X3, y3, groups, cv=GroupKFold(n_splits=3))\n",
    "print(\"Cross-validation scores:\\n{}\".format(scores))\n",
    "X3\n",
    "y3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Back to the example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` provides three functions: `cross_val_score`, `cross_val_predict`, and [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html). The latter provides more information regarding fitting time, training and testing scores. I can also return multiple scores at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(pipe.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='lbfgs', multi_class='auto',\n",
    "                                        max_iter=1000, random_state=42))\n",
    "scores = cross_validate(pipe, X, y, cv=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the cross-validate function, we can quickly check the training and testing scores and make a quick plot using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean times and scores:\\n\", df_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Exercise\n",
    "\n",
    "Use the pipeline of the previous exercise and make a cross-validation instead of a single split evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000))\n",
    "scores = cross_validate(pipe, X_breast, y_breast, scoring='balanced_accuracy', cv=3, return_train_score=True)\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores[['train_score', 'test_score']].boxplot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyper-parameters optimization: fine-tune the inside of a pipeline using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you would like to find the parameters of a component of the pipeline which lead to the best accuracy. We already saw that we could check the parameters of a pipeline using `get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Using pipelines in grid searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameters can be optimized by an exhaustive search. [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) provides such utility and does a cross-validated grid-search over a parameter grid.\n",
    "\n",
    "Let's give an example in which we would like to optimize the `C` and `penalty` parameters of the `LogisticRegression` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='saga', multi_class='auto',\n",
    "                                        random_state=42, max_iter=5000))\n",
    "param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n",
    "              'logisticregression__penalty': ['l2', 'l1']}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1, return_train_score=True)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitting the grid-search object, it finds the best possible parameter combination on the training set (using cross-validation). We can introspect the results of the grid-search by accessing the attribute `cv_results_`. It allows us to check the effect of the parameters on the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid = pd.DataFrame(grid.cv_results_)\n",
    "df_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "scores = np.array(df_grid.mean_test_score).reshape(3, 2)\n",
    "\n",
    "# plot the mean cross-validation scores\n",
    "mglearn.tools.heatmap(scores, xlabel='Penalty', xticklabels=param_grid['logisticregression__penalty'],\n",
    "                      ylabel='C', yticklabels=param_grid['logisticregression__C'], cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the grid-search object is also behaving as an estimator. Once it is fitted, calling `score` will fix the hyper-parameters to the best parameters found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best estimator:\\n{}\".format(grid.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic regression step:\\n{}\".format(\n",
    "      grid.best_estimator_.named_steps[\"logisticregression\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic regression coefficients:\\n{}\".format(\n",
    "      grid.best_estimator_.named_steps[\"logisticregression\"].coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides this is possible to call the grid-search as any other classifier to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = grid.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(grid.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to know, we only make the fitting of the grid-search on a single split. However, as previously stated, we might be interested to make an outer cross-validation to estimate the performance of the model and different sample of data and check the potential variation in performance. Since grid-search is an estimator, we can use it directly within the `cross_validate` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(grid, X, y, cv=3, n_jobs=-1, return_train_score=True)\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Grid-searching preprocessing steps and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    boston.data, boston.target, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pipe = make_pipeline(PolynomialFeatures(), StandardScaler(),Ridge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'polynomialfeatures__degree': [1, 2, 3],\n",
    "              'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.tools.heatmap(grid.cv_results_['mean_test_score'].reshape(3, -1),\n",
    "                      xlabel=\"ridge__alpha\", ylabel=\"polynomialfeatures__degree\",\n",
    "                      xticklabels=param_grid['ridge__alpha'],\n",
    "                      yticklabels=param_grid['polynomialfeatures__degree'], vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test-set score: {:.2f}\".format(grid.score(X_test2, y_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "pipe = make_pipeline(StandardScaler(), Ridge())\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train2, y_train2)\n",
    "print(\"Score without poly features: {:.2f}\".format(grid.score(X_test2, y_test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.3 Grid-searching which model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier': [SVC()], 'preprocessing': [StandardScaler(), None],\n",
    "     'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "     'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "    {'classifier': [RandomForestClassifier(n_estimators=100)],\n",
    "     'preprocessing': [None], 'classifier__max_features': [1, 2, 3]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_breast_train, X_breast_test, y_breast_train, y_breast_test = train_test_split(\n",
    "    X_breast, y_breast, random_state=0)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_breast_train, y_breast_train)\n",
    "\n",
    "print(\"Best params:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Test-set score: {:.2f}\".format(grid.score(X_breast_test, y_breast_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.4 Exercise\n",
    "\n",
    "Reuse the previous pipeline for the breast dataset and make a grid-search to evaluate the difference between a `hinge` and `log` loss. Besides, fine-tune the `penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000))\n",
    "param_grid = {'sgdclassifier__loss': ['hinge', 'log'],\n",
    "              'sgdclassifier__penalty': ['l2', 'l1']}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "scores = cross_validate(grid, X_breast, y_breast, scoring='balanced_accuracy', cv=3, return_train_score=True)\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores[['train_score', 'test_score']].boxplot()\n",
    "\n",
    "grid.fit(X_breast_train, y_breast_train)\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary: my scikit-learn pipeline in less than 10 lines of code (skipping the import statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='saga', multi_class='auto', random_state=42, max_iter=5000))\n",
    "param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n",
    "              'logisticregression__penalty': ['l2', 'l1']}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "scores = pd.DataFrame(cross_validate(grid, X, y, cv=3, n_jobs=-1, return_train_score=True))\n",
    "scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
